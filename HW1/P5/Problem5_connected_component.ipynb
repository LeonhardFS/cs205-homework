{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import matplotlib.ticker as ticker   \n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# shortest path code is in this module\n",
    "from P5_sssp import *\n",
    "\n",
    "# setup spark\n",
    "conf = SparkConf().setAppName('WikiGraph')\n",
    "sc = SparkContext(conf=conf, pyFiles=['P5_sssp.py'])\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare test graph\n",
    "# graph should have no jumps in node IDs! (maybe remap before!)\n",
    "testgraph = [(1, [2, 3]), (2, [1, 3]), (3, [1,2,4]), (4, [3]), (5, [6, 7]), (6, [5]), (7, [5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(testgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform to structure (init)\n",
    "rddA = rdd.map(lambda x: (x[0], (x[1], x[0])))\n",
    "maxNodeID = rddA.map(lambda x: x[0]).max()\n",
    "minNodeID = rddA.map(lambda x: x[0]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddA.map(lambda x: x[0]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ([2, 3], 1)),\n",
       " (2, ([1, 3], 2)),\n",
       " (3, ([1, 2, 4], 3)),\n",
       " (4, ([3], 4)),\n",
       " (5, ([6, 7], 5)),\n",
       " (6, ([5], 6)),\n",
       " (7, ([5], 7))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddA.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to check whether the partitioning in connected components changed\n",
    "def checkForPartitionChange(newSizes, oldSizes):\n",
    "    partitionChanged = False\n",
    "\n",
    "    # quick check if length of the dict is different to previous step\n",
    "    # the partitions changed!\n",
    "    if len(oldSizes.items()) != len(newSizes.items()):\n",
    "        partitionChanged = True\n",
    "    else:\n",
    "        # the size did not change, but what about some internal shifting?\n",
    "        # ==> check for each connected component if size changed!\n",
    "        for ID in range(minNodeID, maxNodeID+1):\n",
    "            # check if for old / new the current ID exists and is equal\n",
    "            # ==> if not, a change happened!\n",
    "            try:\n",
    "                sizeOld = oldSizes[ID]\n",
    "                sizeNew = newSizes[ID]\n",
    "\n",
    "                if sizeOld != sizeNew:\n",
    "                    partitionChanged = True\n",
    "                    break\n",
    "            except KeyError:\n",
    "                partitionChanged = True\n",
    "                break\n",
    "                \n",
    "    return partitionChanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "rdd = rddA\n",
    "\n",
    "\n",
    "# this is the algorithm (Pegasus after ...)\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    # compute sizes of connected components\n",
    "    rddComponents = rdd.map(lambda x: x[1][1])\n",
    "    oldSizes = rddComponents.countByValue()\n",
    "\n",
    "\n",
    "    # mapper / expander\n",
    "    rdd = rdd.flatMap(lambda x: [x] + [(y, ([], x[1][1])) for y in x[1][0]])\n",
    "\n",
    "    # reducer (as there is only !one! element with the whole adj. list, we can speed it up here!)\n",
    "    rdd = rdd.reduceByKey(lambda a,b: (a[0] + b[0], min(a[1], b[1])))\n",
    "\n",
    "    # determine if number of partitions changed! (0 is a dummy value to construct an pair rdd)\n",
    "    rddComponents = rdd.map(lambda x: x[1][1])\n",
    "    newSizes = rddComponents.countByValue()\n",
    "\n",
    "    # if partition changed, one more round!\n",
    "    done = not checkForPartitionChange(newSizes, oldSizes)\n",
    "\n",
    "    oldSizes = newSizes\n",
    "\n",
    "# reconstruct connected components\n",
    "componentList = rdd.map(lambda x: (x[1][1], x[0])).sortByKey().groupByKey().map(lambda x: sorted(list(x[1]))).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform PEGASUS algorithm after ...\n",
    "def connectedComponents(rddIn):\n",
    "    \n",
    "    # transform to structure (init)\n",
    "    rdd = rddIn.map(lambda x: (x[0], (x[1], x[0])))\n",
    "    maxNodeID = rdd.map(lambda x: x[0]).max()\n",
    "    minNodeID = rdd.map(lambda x: x[0]).min()\n",
    "    \n",
    "    # helper function to check whether the partitioning in connected components changed\n",
    "    def checkForPartitionChange(newSizes, oldSizes):\n",
    "        partitionChanged = False\n",
    "\n",
    "        # quick check if length of the dict is different to previous step\n",
    "        # the partitions changed!\n",
    "        if len(oldSizes.items()) != len(newSizes.items()):\n",
    "            partitionChanged = True\n",
    "        else:\n",
    "            # the size did not change, but what about some internal shifting?\n",
    "            # ==> check for each connected component if size changed!\n",
    "            for ID in range(minNodeID, maxNodeID+1):\n",
    "                # check if for old / new the current ID exists and is equal\n",
    "                # ==> if not, a change happened!\n",
    "                try:\n",
    "                    sizeOld = oldSizes[ID]\n",
    "                    sizeNew = newSizes[ID]\n",
    "\n",
    "                    if sizeOld != sizeNew:\n",
    "                        partitionChanged = True\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    partitionChanged = True\n",
    "                    break\n",
    "\n",
    "        return partitionChanged\n",
    "    \n",
    "    \n",
    "    # this is the algorithm (Pegasus after ...)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # compute sizes of connected components\n",
    "        rddComponents = rdd.map(lambda x: x[1][1])\n",
    "        oldSizes = rddComponents.countByValue()\n",
    "\n",
    "\n",
    "        # mapper / expander\n",
    "        rdd = rdd.flatMap(lambda x: [x] + [(y, ([], x[1][1])) for y in x[1][0]])\n",
    "\n",
    "        # reducer (as there is only !one! element with the whole adj. list, we can speed it up here!)\n",
    "        rdd = rdd.reduceByKey(lambda a,b: (a[0] + b[0], min(a[1], b[1])))\n",
    "\n",
    "        # determine if number of partitions changed! (0 is a dummy value to construct an pair rdd)\n",
    "        rddComponents = rdd.map(lambda x: x[1][1])\n",
    "        newSizes = rddComponents.countByValue()\n",
    "\n",
    "        # if partition changed, one more round!\n",
    "        done = not checkForPartitionChange(newSizes, oldSizes)\n",
    "\n",
    "        oldSizes = newSizes\n",
    "\n",
    "    # reconstruct connected components\n",
    "    componentList = rdd.map(lambda x: (x[1][1], x[0])).sortByKey().groupByKey().map(lambda x: sorted(list(x[1]))).collect()\n",
    "\n",
    "    return componentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test run on rdd!\n",
    "rddTest = sc.parallelize(testgraph)\n",
    "\n",
    "cList = connectedComponents(rddTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [5, 6, 7]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
